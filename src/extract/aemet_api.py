import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib3.poolmanager import PoolManager
import pandas as pd
import json
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Callable, Any
from dotenv import load_dotenv
from pathlib import Path
import math
import time
import random
from functools import wraps
from collections import deque
import threading
import ssl

from .dto import DailyWeatherDTO, CityConfigDTO
import yaml

# Cargar API key
load_dotenv()
#AEMET_API_KEY = "eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJkYW5pZWwuYmFyYmVyb2pAZ21haWwuY29tIiwianRpIjoiYjcwNGI1ZTEtMTY2My00MmQ1LWIyOTUtZmVhYTExNGVlM2I3IiwiaXNzIjoiQUVNRVQiLCJpYXQiOjE3NDk3MTYyNTQsInVzZXJJZCI6ImI3MDRiNWUxLTE2NjMtNDJkNS1iMjk1LWZlYWExMTRlZTNiNyIsInJvbGUiOiIifQ.Mf_o4q6TWGaT8pwQCZW-sOeuOi0wNyBUxyOM24jgaRg"
AEMET_API_KEY = "eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJkYW5pZWwuYmFyYmVyb2pAZ21haWwuY29tIiwianRpIjoiNzZjM2ZkODMtYjVlZi00YTQ3LWI4M2QtMTc5MjJjMzZlMjMxIiwiaXNzIjoiQUVNRVQiLCJpYXQiOjE3NTYwMzE4MTcsInVzZXJJZCI6Ijc2YzNmZDgzLWI1ZWYtNGE0Ny1iODNkLTE3OTIyYzM2ZTIzMSIsInJvbGUiOiIifQ.rVEOBWGmTc3utFTnYY27SB_tVfJmIPXGIIn1Rp80MKI"

AEMET_BASE_URL = "https://opendata.aemet.es/opendata/api"
HEADERS = {"api_key": AEMET_API_KEY}

# Paths
UTILS_PATH = Path("data/utils")
STATIONS_FILE = UTILS_PATH / "aemet_stations.json"

class RateLimiter:
    """
    Rate limiter thread-safe para controlar peticiones a APIs.
    Implementa sliding window rate limiting.
    """
    
    def __init__(self, max_requests: int, time_window: float):
        """
        Args:
            max_requests: N√∫mero m√°ximo de peticiones permitidas
            time_window: Ventana de tiempo en segundos
        """
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = deque()
        self.lock = threading.Lock()
    
    def acquire(self, wait: bool = True) -> bool:
        """
        Intenta adquirir un slot para una petici√≥n.
        
        Args:
            wait: Si esperar hasta que haya un slot disponible
            
        Returns:
            True si se adquiri√≥ el slot, False si no se pudo
        """
        with self.lock:
            now = time.time()
            
            # Limpiar peticiones antiguas fuera de la ventana de tiempo
            while self.requests and now - self.requests[0] > self.time_window:
                self.requests.popleft()
            
            # Verificar si hay espacio disponible
            if len(self.requests) < self.max_requests:
                self.requests.append(now)
                return True
            
            if not wait:
                return False
            
            # Calcular cu√°nto esperar hasta que haya un slot disponible
            oldest_request = self.requests[0]
            wait_time = self.time_window - (now - oldest_request)
            
            if wait_time > 0:
                print(f"Rate limit alcanzado. Esperando {wait_time:.2f} segundos...")
                time.sleep(wait_time)
                
                # Limpiar y a√±adir la nueva petici√≥n
                self.requests.popleft()
                self.requests.append(time.time())
                return True
            
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas del rate limiter"""
        with self.lock:
            now = time.time()
            # Limpiar peticiones antiguas
            while self.requests and now - self.requests[0] > self.time_window:
                self.requests.popleft()
            
            return {
                "current_requests": len(self.requests),
                "max_requests": self.max_requests,
                "time_window": self.time_window,
                "available_slots": max(0, self.max_requests - len(self.requests))
            }

# Configuraci√≥n de rate limiting para AEMET
# Basado en la documentaci√≥n de AEMET: ~100 peticiones por minuto
AEMET_RATE_LIMITER = RateLimiter(max_requests=90, time_window=60.0)  # 90 peticiones por minuto (conservador)

class ConnectionPoolManager:
    """
    Gestor de connection pools para optimizar las conexiones HTTP.
    Proporciona configuraci√≥n optimizada para diferentes tipos de peticiones.
    """
    
    def __init__(self, 
                 pool_connections: int = 10,
                 pool_maxsize: int = 20,
                 max_retries: int = 3,
                 backoff_factor: float = 0.3,
                 status_forcelist: List[int] = None,
                 timeout: tuple = (5, 30)):
        """
        Args:
            pool_connections: N√∫mero de pools de conexi√≥n
            pool_maxsize: Tama√±o m√°ximo del pool por host
            max_retries: N√∫mero m√°ximo de reintentos
            backoff_factor: Factor de backoff para reintentos
            status_forcelist: Lista de c√≥digos de estado para reintentar
            timeout: Tupla (connect_timeout, read_timeout)
        """
        self.pool_connections = pool_connections
        self.pool_maxsize = pool_maxsize
        self.max_retries = max_retries
        self.backoff_factor = backoff_factor
        self.status_forcelist = status_forcelist or [429, 500, 502, 503, 504]
        self.timeout = timeout
        
        # Crear la sesi√≥n con configuraci√≥n optimizada
        self.session = self._create_optimized_session()
    
    def _create_optimized_session(self) -> requests.Session:
        """Crea una sesi√≥n HTTP optimizada con connection pooling"""
        
        # Crear sesi√≥n
        session = requests.Session()
        
        # Configurar retry strategy
        retry_strategy = Retry(
            total=self.max_retries,
            status_forcelist=self.status_forcelist,
            backoff_factor=self.backoff_factor,
            allowed_methods=["HEAD", "GET", "OPTIONS", "POST"]
        )
        
        # Crear adapter personalizado
        adapter = HTTPAdapter(
            pool_connections=self.pool_connections,
            pool_maxsize=self.pool_maxsize,
            max_retries=retry_strategy,
            pool_block=False
        )
        
        # Montar el adapter en la sesi√≥n
        session.mount("http://", adapter)
        session.mount("https://", adapter)
        
        # Configurar headers por defecto
        session.headers.update({
            'User-Agent': 'MeteoPanda/1.0 (Weather Data Extractor)',
            'Accept': 'application/json',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive'
        })
        
        return session
    
    def get_session(self) -> requests.Session:
        """Retorna la sesi√≥n configurada"""
        return self.session
    
    def request(self, method: str, url: str, **kwargs) -> requests.Response:
        """
        Realiza una petici√≥n HTTP usando la sesi√≥n optimizada.
        
        Args:
            method: M√©todo HTTP (GET, POST, etc.)
            url: URL de la petici√≥n
            **kwargs: Argumentos adicionales para requests
            
        Returns:
            Response object
        """
        # Configurar timeout si no est√° especificado
        if 'timeout' not in kwargs:
            kwargs['timeout'] = self.timeout
        
        return self.session.request(method, url, **kwargs)
    
    def get(self, url: str, **kwargs) -> requests.Response:
        """Realiza una petici√≥n GET"""
        return self.request('GET', url, **kwargs)
    
    def post(self, url: str, **kwargs) -> requests.Response:
        """Realiza una petici√≥n POST"""
        return self.request('POST', url, **kwargs)
    
    def close(self):
        """Cierra la sesi√≥n y libera recursos"""
        if self.session:
            self.session.close()
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas del connection pool"""
        try:
            # Obtener estad√≠sticas del pool manager
            pool_manager = self.session.adapters['https://'].poolmanager
            
            return {
                "pool_connections": self.pool_connections,
                "pool_maxsize": self.pool_maxsize,
                "active_connections": len(pool_manager.pools),
                "timeout": self.timeout,
                "retry_config": {
                    "max_retries": self.max_retries,
                    "backoff_factor": self.backoff_factor,
                    "status_forcelist": self.status_forcelist
                }
            }
        except Exception as e:
            return {
                "error": f"No se pudieron obtener estad√≠sticas: {e}",
                "pool_connections": self.pool_connections,
                "pool_maxsize": self.pool_maxsize
            }

# Configuraci√≥n del connection pool para AEMET
AEMET_CONNECTION_POOL = ConnectionPoolManager(
    pool_connections=10,      # 10 pools de conexi√≥n
    pool_maxsize=20,          # 20 conexiones m√°ximas por host
    max_retries=3,            # 3 reintentos
    backoff_factor=0.3,       # Backoff exponencial
    timeout=(5, 30)           # 5s connect, 30s read
)

def with_rate_limiting(rate_limiter: RateLimiter = AEMET_RATE_LIMITER):
    """
    Decorador para aplicar rate limiting a funciones que hacen peticiones HTTP.
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            # Adquirir slot del rate limiter
            if not rate_limiter.acquire(wait=True):
                raise Exception("No se pudo adquirir slot del rate limiter")
            
            # Ejecutar la funci√≥n
            result = func(*args, **kwargs)
            
            # Opcional: mostrar estad√≠sticas
            stats = rate_limiter.get_stats()
            if stats["available_slots"] < 10:  # Solo mostrar si quedan pocos slots
                print(f"Rate limiter stats: {stats['current_requests']}/{stats['max_requests']} peticiones en uso")
            
            return result
        return wrapper
    return decorator


def log_rate_limiter_status():
    """
    Funci√≥n para mostrar el estado actual del rate limiter.
    √ötil para debugging y monitoreo.
    """
    stats = get_rate_limiter_stats()
    print(f"üìä Rate Limiter Status: {stats['current_requests']}/{stats['max_requests']} peticiones activas")
    print(f"   Slots disponibles: {stats['available_slots']}")
    print(f"   Ventana de tiempo: {stats['time_window']} segundos")
    
    # Calcular porcentaje de uso
    usage_percentage = (stats['current_requests'] / stats['max_requests']) * 100
    if usage_percentage > 80:
        print(f"   ‚ö†Ô∏è  Uso alto: {usage_percentage:.1f}%")
    elif usage_percentage > 60:
        print(f"   ‚ö° Uso moderado: {usage_percentage:.1f}%")
    else:
        print(f"   ‚úÖ Uso normal: {usage_percentage:.1f}%")


def get_optimal_rate_limiter_config() -> Dict[str, Any]:
    """
    Retorna la configuraci√≥n √≥ptima del rate limiter basada en la documentaci√≥n de AEMET.
    """
    return {
        "max_requests": 90,
        "time_window": 60.0,
        "description": "90 peticiones por minuto (conservador para evitar 429)",
        "recommendation": "Ajustar seg√∫n el comportamiento observado de la API"
    }


def get_connection_pool_stats() -> Dict[str, Any]:
    """
    Obtiene estad√≠sticas del connection pool de AEMET.
    """
    return AEMET_CONNECTION_POOL.get_pool_stats()


def log_connection_pool_status():
    """
    Funci√≥n para mostrar el estado actual del connection pool.
    √ötil para debugging y monitoreo.
    """
    stats = get_connection_pool_stats()
    
    print(f"üîó Connection Pool Status:")
    print(f"   Pool connections: {stats['pool_connections']}")
    print(f"   Pool maxsize: {stats['pool_maxsize']}")
    print(f"   Active connections: {stats.get('active_connections', 'N/A')}")
    print(f"   Timeout: {stats['timeout']}")
    
    if 'retry_config' in stats:
        retry = stats['retry_config']
        print(f"   Retry config: {retry['max_retries']} max, {retry['backoff_factor']} backoff")
        print(f"   Retry status codes: {retry['status_forcelist']}")


def configure_connection_pool(
    pool_connections: int = None,
    pool_maxsize: int = None,
    max_retries: int = None,
    backoff_factor: float = None,
    timeout: tuple = None
):
    """
    Configura el connection pool con nuevos par√°metros.
    
    Args:
        pool_connections: N√∫mero de pools de conexi√≥n
        pool_maxsize: Tama√±o m√°ximo del pool por host
        max_retries: N√∫mero m√°ximo de reintentos
        backoff_factor: Factor de backoff para reintentos
        timeout: Tupla (connect_timeout, read_timeout)
    """
    global AEMET_CONNECTION_POOL
    
    # Cerrar la sesi√≥n actual
    AEMET_CONNECTION_POOL.close()
    
    # Obtener valores actuales si no se especifican
    current_stats = AEMET_CONNECTION_POOL.get_pool_stats()
    
    pool_connections = pool_connections or current_stats['pool_connections']
    pool_maxsize = pool_maxsize or current_stats['pool_maxsize']
    max_retries = max_retries or current_stats['retry_config']['max_retries']
    backoff_factor = backoff_factor or current_stats['retry_config']['backoff_factor']
    timeout = timeout or current_stats['timeout']
    
    # Crear nueva configuraci√≥n
    AEMET_CONNECTION_POOL = ConnectionPoolManager(
        pool_connections=pool_connections,
        pool_maxsize=pool_maxsize,
        max_retries=max_retries,
        backoff_factor=backoff_factor,
        timeout=timeout
    )
    
    print(f"Connection pool configurado: {pool_connections} pools, {pool_maxsize} maxsize, {timeout} timeout")


def get_optimal_connection_pool_config() -> Dict[str, Any]:
    """
    Retorna la configuraci√≥n √≥ptima del connection pool para AEMET.
    """
    return {
        "pool_connections": 10,
        "pool_maxsize": 20,
        "max_retries": 3,
        "backoff_factor": 0.3,
        "timeout": (5, 30),
        "description": "Configuraci√≥n optimizada para extracci√≥n de datos meteorol√≥gicos",
        "recommendation": "Ajustar seg√∫n el volumen de peticiones y latencia de red"
    }


def cleanup_connection_pool():
    """
    Limpia y cierra el connection pool para liberar recursos.
    √ötil al finalizar la aplicaci√≥n o para reiniciar conexiones.
    """
    AEMET_CONNECTION_POOL.close()
    print("Connection pool cerrado y recursos liberados")


def get_rate_limiter_stats() -> Dict[str, Any]:
    """
    Obtiene estad√≠sticas del rate limiter de AEMET.
    """
    return AEMET_RATE_LIMITER.get_stats()


def reset_rate_limiter():
    """
    Resetea el rate limiter (√∫til para testing o reinicio de sesi√≥n).
    """
    with AEMET_RATE_LIMITER.lock:
        AEMET_RATE_LIMITER.requests.clear()
    print("Rate limiter reseteado")


def configure_rate_limiter(max_requests: int, time_window: float):
    """
    Configura el rate limiter con nuevos par√°metros.
    
    Args:
        max_requests: N√∫mero m√°ximo de peticiones permitidas
        time_window: Ventana de tiempo en segundos
    """
    global AEMET_RATE_LIMITER
    AEMET_RATE_LIMITER = RateLimiter(max_requests, time_window)
    print(f"Rate limiter configurado: {max_requests} peticiones por {time_window} segundos")

def retry_with_exponential_backoff(
    max_retries: int = 3,
    base_delay: float = 1.0,
    max_delay: float = 60.0,
    exponential_base: float = 2.0,
    jitter: bool = True,
    retry_exceptions: tuple = (requests.RequestException, ConnectionError, TimeoutError)
):
    """
    Decorador para implementar retry logic con backoff exponencial.
    
    Args:
        max_retries: N√∫mero m√°ximo de reintentos
        base_delay: Delay inicial en segundos
        max_delay: Delay m√°ximo en segundos
        exponential_base: Base para el c√°lculo exponencial
        jitter: Si a√±adir jitter aleatorio para evitar thundering herd
        retry_exceptions: Tupla de excepciones que deben provocar reintento
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except retry_exceptions as e:
                    last_exception = e
                    
                    if attempt == max_retries:
                        # √öltimo intento fall√≥, re-raise la excepci√≥n
                        print(f"Error despu√©s de {max_retries + 1} intentos: {e}")
                        raise
                    
                    # Calcular delay con backoff exponencial
                    delay = min(base_delay * (exponential_base ** attempt), max_delay)
                    
                    # A√±adir jitter si est√° habilitado
                    if jitter:
                        delay = delay * (0.5 + random.random() * 0.5)
                    
                    print(f"Intento {attempt + 1} fall√≥: {e}. Reintentando en {delay:.2f} segundos...")
                    time.sleep(delay)
            
            # Nunca deber√≠a llegar aqu√≠, pero por si acaso
            raise last_exception
            
        return wrapper
    return decorator


def retry_with_http_status_handling(
    max_retries: int = 3,
    base_delay: float = 1.0,
    max_delay: float = 60.0,
    exponential_base: float = 2.0,
    jitter: bool = True
):
    """
    Decorador espec√≠fico para manejar errores HTTP con diferentes estrategias seg√∫n el c√≥digo de estado.
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return func(*args, **kwargs)
                except requests.HTTPError as e:
                    last_exception = e
                    response = e.response
                    
                    if attempt == max_retries:
                        print(f"Error HTTP despu√©s de {max_retries + 1} intentos: {e}")
                        raise
                    
                    # Manejar diferentes c√≥digos de estado
                    if response.status_code == 429:  # Too Many Requests
                        # Para rate limiting, usar un delay m√°s largo
                        delay = min(30.0 * (exponential_base ** attempt), max_delay)
                        print(f"Rate limit alcanzado (429). Esperando {delay:.2f} segundos antes del reintento {attempt + 1}...")
                    elif response.status_code in [500, 502, 503, 504]:  # Server errors
                        # Para errores del servidor, usar delay normal
                        delay = min(base_delay * (exponential_base ** attempt), max_delay)
                        print(f"Error del servidor ({response.status_code}). Reintentando en {delay:.2f} segundos...")
                    else:
                        # Para otros errores HTTP, no reintentar
                        print(f"Error HTTP {response.status_code}: {e}")
                        raise
                    
                    # A√±adir jitter si est√° habilitado
                    if jitter:
                        delay = delay * (0.5 + random.random() * 0.5)
                    
                    time.sleep(delay)
                    
                except (requests.RequestException, ConnectionError, TimeoutError) as e:
                    last_exception = e
                    
                    if attempt == max_retries:
                        print(f"Error de conexi√≥n despu√©s de {max_retries + 1} intentos: {e}")
                        raise
                    
                    # Para errores de conexi√≥n, usar delay normal
                    delay = min(base_delay * (exponential_base ** attempt), max_delay)
                    
                    if jitter:
                        delay = delay * (0.5 + random.random() * 0.5)
                    
                    print(f"Error de conexi√≥n en intento {attempt + 1}: {e}. Reintentando en {delay:.2f} segundos...")
                    time.sleep(delay)
            
            raise last_exception
            
        return wrapper
    return decorator


@with_rate_limiting()
def make_aemet_request(url: str, description: str = "petici√≥n AEMET") -> requests.Response:
    """
    Funci√≥n helper para hacer peticiones a AEMET con manejo de errores espec√≠ficos.
    Usa connection pooling para optimizar las conexiones HTTP.
    """
    try:
        # Usar el connection pool en lugar de requests directo
        response = AEMET_CONNECTION_POOL.get(url, headers=HEADERS)
        
        # Si es un error HTTP, raise la excepci√≥n para que el decorador la maneje
        if response.status_code >= 400:
            response.raise_for_status()
            
        return response
        
    except requests.exceptions.Timeout:
        print(f"Timeout en {description}")
        raise
    except requests.exceptions.ConnectionError:
        print(f"Error de conexi√≥n en {description}")
        raise
    except requests.exceptions.RequestException as e:
        print(f"Error en {description}: {e}")
        raise

@retry_with_http_status_handling(max_retries=3, base_delay=2.0, max_delay=60.0)
def download_stations_data() -> Dict:
    """
    Descarga los datos de las estaciones de AEMET y los guarda localmente.
    Devuelve los datos de las estaciones como un diccionario.
    """
    url = f"{AEMET_BASE_URL}/valores/climatologicos/inventarioestaciones/todasestaciones"
    
    # Primera petici√≥n para obtener el endpoint de los datos
    response = make_aemet_request(url, "descarga de estaciones - primera petici√≥n")
    metadata = response.json()
    
    if metadata.get("estado") != 200:
        print(f"Error en la respuesta de AEMET: {metadata.get('descripcion')}")
        return {}
        
    # Segunda petici√≥n para obtener los datos reales
    data_url = metadata.get("datos")
    if not data_url:
        print("No se encontr√≥ la URL de los datos en la respuesta")
        return {}
        
    data_response = make_aemet_request(data_url, "descarga de estaciones - segunda petici√≥n")
    stations = data_response.json()
    
    # Create utils directory if it doesn't exist
    UTILS_PATH.mkdir(parents=True, exist_ok=True)
    
    # Save stations data
    with open(STATIONS_FILE, 'w', encoding='utf-8') as f:
        json.dump(stations, f, ensure_ascii=False, indent=2)
        
    return stations

def load_stations_data() -> Dict:
    """
    Carga los datos de las estaciones de AEMET desde un archivo local o los descarga si no est√°n disponibles.
    Devuelve los datos de las estaciones como un diccionario.
    """
    if not STATIONS_FILE.exists():
        return download_stations_data()
    
    try:
        with open(STATIONS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error cargando datos de estaciones: {e}")
        return download_stations_data()

def dms_to_decimal(dms_str: str) -> float:
    """
    Convierte coordenadas de formato DMS (Grados, Minutos, Segundos) a decimal.
    """
    try:
        # Extraer la direcci√≥n (√∫ltimo car√°cter)
        direction = dms_str[-1].upper()
        # Extraer los n√∫meros
        dms = dms_str[:-1]
        
        # Convertir a grados, minutos y segundos
        degrees = int(dms[:2])
        minutes = int(dms[2:4])
        seconds = int(dms[4:])
        
        # Calcular decimal
        decimal = degrees + minutes/60 + seconds/3600
        
        # Ajustar seg√∫n la direcci√≥n
        if direction in ['S', 'W']:
            decimal = -decimal
            
        return decimal
    except Exception as e:
        print(f"Error convirtiendo coordenadas DMS a decimal: {e}")
        return 0.0

def get_nearest_station(lat: float, lon: float, stations: List[Dict]) -> Optional[str]:
    """
    Encuentra la estaci√≥n m√°s cercana usando la distancia euclidea.
    """
    if not stations:
        return None
    
    min_distance = float('inf')
    nearest_station = None
    
    for station in stations:
        try:
            # Convertir coordenadas de DMS a decimal
            station_lat = dms_to_decimal(station.get('latitud', '0'))
            station_lon = dms_to_decimal(station.get('longitud', '0'))
            
            # Calcular distancia euclidiana
            distance = math.sqrt((lat - station_lat)**2 + (lon - station_lon)**2)
            
            if distance < min_distance:
                min_distance = distance
                nearest_station = station['indicativo']
        except (ValueError, KeyError) as e:
            print(f"Error procesando coordenadas de estaci√≥n: {e}")
            continue
    
    return nearest_station

def get_station_id(lat: float, lon: float) -> Optional[str]:
    """
    Obtiene el ID de la estaci√≥n AEMET m√°s cercana a las coordenadas dadas.
    """
    stations = load_stations_data()
    return get_nearest_station(lat, lon, stations)

def load_config(path: str) -> tuple[List[CityConfigDTO], str, str]:
    with open(path, "r") as f:
        cfg = yaml.safe_load(f)
    cities = [CityConfigDTO(**c) for c in cfg["cities"]]
    return cfg["region"], cities, cfg["start_date"], cfg["end_date"]

@retry_with_http_status_handling(max_retries=3, base_delay=2.0, max_delay=60.0)
def _fetch_data_batch(station_id: str, start_date: str, end_date: str) -> pd.DataFrame:
    """
    Funci√≥n interna para obtener datos de AEMET para un rango de fechas espec√≠fico.
    """
    url = f"{AEMET_BASE_URL}/valores/climatologicos/diarios/datos/fechaini/{start_date}/fechafin/{end_date}/estacion/{station_id}"
    
    # Primera petici√≥n para obtener la URL de los datos
    response = make_aemet_request(url, f"primera petici√≥n para {station_id} ({start_date} - {end_date})")
    metadata = response.json()
    print(f"Respuesta de AEMET 1 para {station_id, start_date, end_date}: {metadata}")
    
    if metadata.get('estado') != 200:
        print(f"Error en la primera respuesta de AEMET: {metadata.get('descripcion')}")
        return pd.DataFrame()
        
    # Segunda petici√≥n para obtener los datos reales
    data_url = metadata.get('datos')
    if not data_url:
        print("Error antes de la segunda respuesta de AEMET: No se encontr√≥ URL de datos en la primera respuesta")
        return pd.DataFrame()
        
    # El rate limiter ya maneja los delays autom√°ticamente
    data_response = make_aemet_request(data_url, f"segunda petici√≥n para {station_id} ({start_date} - {end_date})")
    raw_data = data_response.json()
    print(f"Respuesta de AEMET 2 para {station_id, start_date, end_date}: {data_response}")
    
    
    # Transformar datos al formato com√∫n
    validated_data = []
    for record in raw_data:
        try:
            def safe_float(value):
                if value is None or value == "" or value == "null" or value == "Ip":
                    return None
                return float(str(value).replace(",", "."))
            
            weather_data = {
                "date": datetime.strptime(record["fecha"], "%Y-%m-%d").date(),
                "tmax": safe_float(record.get("tmax")),
                "tmin": safe_float(record.get("tmin")),
                "tavg": safe_float(record.get("tmed")),
                "prcp": safe_float(record.get("prec")),
                "wdir": safe_float(record.get("dir")),
                "wspd": safe_float(record.get("velmedia")),
                "wpgt": safe_float(record.get("racha")),
                "pres": None,  # No existe en AEMET
                "snow": None,  # No existe en AEMET
                "tsun": None,  # No existe en AEMET
                "rhum": None,  # No existe en AEMET
                "station": station_id
            }
            validated_data.append(DailyWeatherDTO(**weather_data).dict())
        except Exception as e:
            print(f"Error al procesar registro: {e}")
            continue
    
    return pd.DataFrame(validated_data)

def fetch_daily_data(station_id: str, start: str, end: str) -> pd.DataFrame:
    """
    Obtiene datos diarios de una estaci√≥n AEMET para un rango de fechas.
    Si el rango es mayor a 6 meses, descarga los datos en batches de 6 meses.
    """
    try:
        # Convertir fechas a datetime para c√°lculos
        start_dt = datetime.strptime(start, "%Y-%m-%d")
        end_dt = datetime.strptime(end, "%Y-%m-%d")
        
        # Calcular diferencia en meses
        months_diff = (end_dt.year - start_dt.year) * 12 + end_dt.month - start_dt.month
        
        if months_diff <= 6:
            # Si es menos de 6 meses, descargar directamente
            start_date = start_dt.strftime("%Y-%m-%dT00:00:00UTC")
            end_date = end_dt.strftime("%Y-%m-%dT00:00:00UTC")
            return _fetch_data_batch(station_id, start_date, end_date)
        else:
            # Si es m√°s de 6 meses, descargar en batches
            all_data = []
            current_start = start_dt
            
            while current_start < end_dt:
                # Calcular fecha final del batch (6 meses despu√©s o end_dt)
                current_end = min(
                    datetime(current_start.year + (current_start.month + 6) // 12,
                            (current_start.month + 6) % 12 or 12,
                            1) - timedelta(days=1),
                    end_dt
                )
                
                # Formatear fechas para la API
                batch_start = current_start.strftime("%Y-%m-%dT00:00:00UTC")
                batch_end = current_end.strftime("%Y-%m-%dT00:00:00UTC")
                
                # Descargar batch
                batch_data = _fetch_data_batch(station_id, batch_start, batch_end)
                if not batch_data.empty:
                    all_data.append(batch_data)
                
                # Mover al siguiente batch
                current_start = current_end + timedelta(days=1)
                
                # El rate limiter ya maneja los delays autom√°ticamente
            
            # Combinar todos los batches
            return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()
            
    except ValueError as e:
        print(f"Error en el formato de fechas: {e}")
        return pd.DataFrame() 